[
  {
    "objectID": "setup.html#google-colab-setup",
    "href": "setup.html#google-colab-setup",
    "title": "Setup",
    "section": "Google Colab Setup",
    "text": "Google Colab Setup"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Preparation",
    "section": "",
    "text": "An introductory workshop for deep learning techniques for Enhanced Forest Inventories (EFIs) presented at the Canadian Cross-Country EFI Checkup.\nGet Started View Schedule"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Data Preparation",
    "section": "Overview",
    "text": "Overview\nThis workshop covers a basic end-to-end deep learning workflow for EFI applications, covering an introduction into deep learning, to data prepartation, and finally a demo of model training, evaluation, and deployment. There will also be some examples of real world forest inventory deep learning applications showcasing some of the possibilities there are with these techniques.\n\nYou will learn\n\nWhat deep learning is and how it can be used for EFIs.\nHow to prepare and read in data for use in deep learning.\nBasics of using the PyTorch deep learning library.\nDeep learning based forest attribute feature extraction.\nTraining a deep learning model for classification tasks.\nValidation and testing of deep learning models."
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Data Preparation",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nComfortable with Python and Jupyter notebooks.\nGoogle Colab will be used for running the live demo."
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "Data Preparation",
    "section": "Instructors",
    "text": "Instructors\n\n\n\n\n\n\n\nName\nAffiliation\n\n\n\n\nBrent A. Murray\nIntegrated Remote Sensing Studio. University of British Columbia\n\n\nHarry Seely\nIntegrated Remote Sensing Studio. University of British Columbia\n\n\nYuwei Cao\nIntegrated Remote Sensing Studio. University of British Columbia"
  },
  {
    "objectID": "04_validation.html#validating-deep-learning-predictions",
    "href": "04_validation.html#validating-deep-learning-predictions",
    "title": "Validation of Deep Learning Derived Forest Inventory Predictions",
    "section": "Validating Deep Learning Predictions",
    "text": "Validating Deep Learning Predictions"
  },
  {
    "objectID": "04_validation.html#examples-of-evaluation-metrics-and-plotting-figures",
    "href": "04_validation.html#examples-of-evaluation-metrics-and-plotting-figures",
    "title": "Validation of Deep Learning Derived Forest Inventory Predictions",
    "section": "Examples of Evaluation Metrics and Plotting Figures",
    "text": "Examples of Evaluation Metrics and Plotting Figures"
  },
  {
    "objectID": "02_data.html#data-preparation-for-use-in-deep-learning",
    "href": "02_data.html#data-preparation-for-use-in-deep-learning",
    "title": "Data Preparation and Loading",
    "section": "Data Preparation for Use in Deep Learning",
    "text": "Data Preparation for Use in Deep Learning"
  },
  {
    "objectID": "02_data.html#loading-data-in-pytorch",
    "href": "02_data.html#loading-data-in-pytorch",
    "title": "Data Preparation and Loading",
    "section": "Loading Data in PyTorch",
    "text": "Loading Data in PyTorch"
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "Introduction to Deep Learning",
    "section": "",
    "text": "The Deep Learning Book"
  },
  {
    "objectID": "01_intro.html#relevant-resources",
    "href": "01_intro.html#relevant-resources",
    "title": "Introduction to Deep Learning",
    "section": "",
    "text": "The Deep Learning Book"
  },
  {
    "objectID": "01_intro.html#what-is-deep-learning",
    "href": "01_intro.html#what-is-deep-learning",
    "title": "Introduction to Deep Learning",
    "section": "What is Deep Learning?",
    "text": "What is Deep Learning?\nDeep learning is a branch of machine learning, and both are forms of artificial intelligence (AI). AI refers to methods that enable machines to mimic human behavior. Machine learning is a subset of AI that uses statistical techniques to allow machines to improve their performance through experience, while deep learning is a subset of machine learning that enables the computation of multi-layered neural networks. A neural network is a term that is used interchangably with deep learning and we will use them both throughout this workshop.\n\n\n\n\n\n\nFigure 1: Different Types of Artificial Intelligence and Common Examples of Each\n\n\n\n\nComponents of a Deep Neural Network\nThere are several key components and terms commonly used to describe a neural network. The depth of a neural network refers to the number of layers in its architecture (the example in Figure 2 has five layers), whereas the width refers to the number of neurons within each layer.\n\n\n\n\n\n\nFigure 2: Components of a Neural Network\n\n\n\nThe most fundamental unit of a deep neural network is the neuron, which serves as the building block of any neural network. A neuron receives a set of inputs (\\(x_i\\)), weights (\\(w_i\\)) and sums them, while adding a bias term (\\(b\\)). These weights and biases are adjustable parameters that the network learns during training.\n\\[\n\\Large y = w_1x_1 + w_2x_2 + b\n\\]\nAnother important part of a neuron is called the activation. The output of the weighted sum (\\(y\\)) is passed through an activation function, which determines the strength of the output and whether the neuron becomes activated or not.\n\n\n\n\n\n\nFigure 3: Components of a Neuron\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are many activation functions, and you are encouraged to resarch which one would be best for your specific use case.\n\n\n\n\nThe Prediction - Feedback Loop\nThe prediction-feedback loop is what makes learning possible as a deep learning model doesn’t just memorize the data, it adapts and generalizes to it. This allows a model to fine-tune how it sees the input data to improve its performace based on the goal and the task.\n\n\n\n\n\n\nFigure 4: Prediction-Feedback Loop\n\n\n\nThis prediction–feedback loop is driven by the goal of the loss function, which guides the model in adjusting its weights and biases to find the optimal solution. The loss function assesses the difference between the true and predicted labels, typically, with the goal to minimize the error between the two. There are different types of loss functions, each providing different feedback to the model. Choosing a loss function depends on the task (e.g., classification, regression), and ensuring that it is appropriate for the problem is a crucial step.\nOver a number of iterations, or epochs, the model adjusts its weights and biases based on the feedback received from the loss function. Eventually, the model can no longer improve given the input data, and at this point, the loss begins to stabilize, indicating that the model has reached its optimal performance.\n\n\n\n\n\n\nFigure 5: Model Adjusting Over Epochs\n\n\n\n\n\nImage Based vs. Point Based Deep Learning"
  },
  {
    "objectID": "01_intro.html#challenges-with-deep-learning",
    "href": "01_intro.html#challenges-with-deep-learning",
    "title": "Introduction to Deep Learning",
    "section": "Challenges with Deep Learning",
    "text": "Challenges with Deep Learning\n\nImplemented in Python\n\n\nMany Models Use Linux"
  },
  {
    "objectID": "01_intro.html#frequently-asked-questions",
    "href": "01_intro.html#frequently-asked-questions",
    "title": "Introduction to Deep Learning",
    "section": "Frequently Asked Questions",
    "text": "Frequently Asked Questions\n\nHow does deep learning differ from machine learning or artifical intelligence?\n\n\nWhat makes deep learning deep?\n\n\nWhat are some advantages and disadvantages of deep learning?\n\n\n\nAdvantages\nDisadvantages\n\n\n\n\nCan produce more accurate results\nRequires A LOT of training data\n\n\n\n\n\nWhen should a deep learning model be used?\nAs the complexity of the data or the task increases deep learning becomes a more benifical option. Raw lidar data for example is a complex dataset and is well suited for deep learning tasks.\n\n\n\n\n\n\nFigure 6: Data and Task Complexity for Deep and Machine Learning\n\n\n\n\n\nWhat computing resources are required to run a deep learning model?"
  },
  {
    "objectID": "03_train.html#training-deep-learning-models-in-pytorch",
    "href": "03_train.html#training-deep-learning-models-in-pytorch",
    "title": "Training Deep Learning Models",
    "section": "Training Deep Learning Models in PyTorch",
    "text": "Training Deep Learning Models in PyTorch\n\nOptimizers\n\n\nLoss Functions"
  },
  {
    "objectID": "05_examples.html#biomass",
    "href": "05_examples.html#biomass",
    "title": "Examples of Deep Learning Forest Inventory Products",
    "section": "Biomass",
    "text": "Biomass"
  },
  {
    "objectID": "05_examples.html#tree-species-composition",
    "href": "05_examples.html#tree-species-composition",
    "title": "Examples of Deep Learning Forest Inventory Products",
    "section": "Tree Species Composition",
    "text": "Tree Species Composition"
  },
  {
    "objectID": "05_examples.html#individual-tree-species",
    "href": "05_examples.html#individual-tree-species",
    "title": "Examples of Deep Learning Forest Inventory Products",
    "section": "Individual Tree Species",
    "text": "Individual Tree Species"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nMaterials\n\n\n\n\n09:00–09:10\nWelcome & Introductions\nHome\n\n\n09:10–09:40\nIntroduction to Deep Learning\n1-Intro\n\n\n09:40–10:15\nData Preparation and Loading\n2-Data\n\n\n10:15–10:30\nBreak\nNA\n\n\n10:30–11:00\nTraining Deep Learning Models\n3-Train\n\n\n11:00–11:20\nValidating Deep Learning Models\n4-Validation\n\n\n11:20–11:50\nExamples of Deep Learning Forest Inventory Products\n5-Examples\n\n\n11:50–12:00\nQuestion & Answer\nNA"
  },
  {
    "objectID": "schedule.html#agenda",
    "href": "schedule.html#agenda",
    "title": "Schedule",
    "section": "",
    "text": "Time\nTopic\nMaterials\n\n\n\n\n09:00–09:10\nWelcome & Introductions\nHome\n\n\n09:10–09:40\nIntroduction to Deep Learning\n1-Intro\n\n\n09:40–10:15\nData Preparation and Loading\n2-Data\n\n\n10:15–10:30\nBreak\nNA\n\n\n10:30–11:00\nTraining Deep Learning Models\n3-Train\n\n\n11:00–11:20\nValidating Deep Learning Models\n4-Validation\n\n\n11:20–11:50\nExamples of Deep Learning Forest Inventory Products\n5-Examples\n\n\n11:50–12:00\nQuestion & Answer\nNA"
  },
  {
    "objectID": "02_data.html#relevant-resources",
    "href": "02_data.html#relevant-resources",
    "title": "Data Preparation",
    "section": "Relevant Resources",
    "text": "Relevant Resources"
  },
  {
    "objectID": "02_data.html#data-download",
    "href": "02_data.html#data-download",
    "title": "Data Preparation",
    "section": "Data download",
    "text": "Data download\nPRF 2018 sample plots have a 14.1 m radius (625 m2)\nThe preprocessed data folder can be downloaded here\nhttps://ln5.sync.com/dl/88a6f5dd0#u24mrtkh-d5dqhart-zrg42shx-jfhhk8u5\nThe original height normalized LiDAR and sample plot data for the PRF can be downloaded below:\nSPL LiDAR: https://opendata.nfis.org/downloads/petawawa/Raster/LiDAR_2018/PRF_benchmarking_harmonized_2018_ALS.zip\nField Plots: https://opendata.nfis.org/downloads/petawawa/Vector/Forest%20Sample%20Plots/SPL2018_EFI_ground_plots.zip"
  },
  {
    "objectID": "02_data.html#extract-lidar-point-clouds-using-the-lidr-package",
    "href": "02_data.html#extract-lidar-point-clouds-using-the-lidr-package",
    "title": "Data Preparation",
    "section": "Extract LiDAR point clouds using the lidR package",
    "text": "Extract LiDAR point clouds using the lidR package\nSet filepaths and other global parameters\n\nPROCESS_LIDAR = FALSE\n\nPLOT_RADIUS = 14.1\n\nPLOT_COORDS_FPATH = 'data/SPL2018_EFI_ground_plots/SPL2018_EFI_ground_plots/PRF_SPL2018_EFI_plots_pts_wgs84.shp'\n\nPLOT_DATA_FPATH = 'data/SPL2018_EFI_ground_plots/SPL2018_EFI_ground_plots/PRF_CNL_SPL_CalibrationData_LiveDeadStems.xlsx'\n\nTREE_SP_CODES_FPATH = 'data/mnrf_sp_codes.csv'\n\nLIDAR_DIR = 'E:/PRF/3_tiled_norm'\n\nPLOT_PC_DIR = \"data/plot_point_clouds\"\n\nLABELS_FPATH = 'data/labels.csv'\n\nZQ95_FPATH = 'data/zq95.csv'\n\nLoad required R packages\n\nlibrary(lidR)\nlibrary(here)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(mapview)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(reticulate)\n\n# Import python numpy module using reticulate in quarto\nnp &lt;- reticulate::import(\"numpy\")\n\nLoad the LiDAR and plot coordinates\n\n#Read the normalized las catalog\nctg &lt;- readLAScatalog(LIDAR_DIR)\n\n#Set some catalog processing parameters\nopt_select(ctg) &lt;- \"xyz\"\nopt_progress(ctg) &lt;- FALSE\n\n#Read the plot coordinates and ensure CRS is correct\nplot_centers &lt;- st_read(here(PLOT_COORDS_FPATH)) %&gt;%\n    st_transform(lidR::crs(ctg)) %&gt;%\n    st_zm() %&gt;%\n    dplyr::rename(plot_id = Plot)\n\nReading layer `PRF_SPL2018_EFI_plots_pts_wgs84' from data source \n  `D:\\Sync\\EFI_DL_Workshop_2026\\DeepLearningEFI\\data\\SPL2018_EFI_ground_plots\\SPL2018_EFI_ground_plots\\PRF_SPL2018_EFI_plots_pts_wgs84.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 249 features and 5 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 299051.1 ymin: 5089954 xmax: 315101 ymax: 5098580\nz_range:       zmin: 0 zmax: 0\nProjected CRS: WGS 84 / UTM zone 18N\n\n#Get vector representation of catalog area\nctg_sf &lt;- st_as_sf(lidR::as.spatial(ctg))\n\nmapview(ctg_sf, layer.name = 'LiDAR Tiles') + mapview(plot_centers, \n                                                      col.regions = 'red', \n                                                      color = 'black',\n                                                      layer.name = 'Ground Plots')\n\n\n\n\n\nDefine functions to process ALS data\n\nextract_pc &lt;- function(coords, ctg){\n\n      x = coords[1]\n      y = coords[2]\n\n      las &lt;- lidR::clip_circle(\n        las = ctg,\n        x = x,\n        y = y,\n        radius = PLOT_RADIUS)\n      \n      return(las)\n\n    }\n\nclean_pc &lt;- function(las) {\n  \n  las &lt;- lidR::filter_duplicates(las)\n  \n  las &lt;- lidR::classify_noise(las, sor(9,2))\n  \n  las &lt;- lidR::filter_poi(las, Classification != LASNOISE)\n  \n  return(las)\n}\n\npc_to_matrix &lt;- function(las){\n\n  pc &lt;- unname(st_coordinates(las))\n\n  return(pc)\n\n}\n\nnormalize_pc_xy &lt;- function(pc){\n\n  pc[, 1] &lt;- pc[, 1] - mean(pc[, 1])\n  pc[, 2] &lt;- pc[, 2] - mean(pc[, 2])\n\n  return(pc)\n}\n\ncalc_pc_zq95 &lt;- function(pc){\n\n    zq95 &lt;- quantile(pc[, 3], probs = 0.95)\n\n    return(zq95)\n\n}\n\nplot_pc &lt;- function(pc){\n\n  pc_df &lt;- as.data.frame(pc)\n  names(pc_df) &lt;- c('x', 'y', 'z')\n\n  p &lt;- plot_ly(pc_df, x = ~x, y = ~y, z = ~z, type = \"scatter3d\", mode = \"markers\",\n             marker = list(size = 3, color = ~z, colorscale = \"Jet\")) %&gt;%\n            layout(title = \"\",\n                  scene = list(\n                    xaxis = list(title = \"\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\"),\n                    yaxis = list(title = \"\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\"),\n                    zaxis = list(title = \"Z\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\")\n                  ))\n\n  return(p)\n\n}\n\nwrite_pc_to_npy &lt;- function(pc, plot_id, pc_out_dir){    \n    \n    pc_np &lt;- np$array(pc, dtype = \"float32\")\n\n    np$save(file.path(here(pc_out_dir), paste0(plot_id, \".npy\")), pc_np)\n\n    return('')\n    \n    }\n\nExtract plot point clouds from full aquisition\n\nif(PROCESS_LIDAR){\n\n  # Get a list of plot coordinates\n  coords &lt;- split(st_coordinates(plot_centers), \n                    seq_len(nrow(plot_centers)))\n\n  # Extract point clouds and store in list\n  pc_ls &lt;- plyr::llply(coords, .fun = extract_pc, ctg = ctg, .progress='text')\n\n  # Clean point clouds\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = clean_pc, .progress='text')\n\n  # Convert point clouds to matrices\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = pc_to_matrix, .progress='text')\n\n  # Normalize point clouds X & Y coordinates (leave Z)\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = normalize_pc_xy, .progress='text')\n\n  # Calculate zq95 for each point cloud to check alignment with plot data later\n  als_derived_zq95_ls &lt;- plyr::llply(pc_ls, .fun = calc_pc_zq95, .progress='text')\n\n  # Ensure the point cloud directory exists\n  dir.create(PLOT_PC_DIR, recursive = TRUE, showWarnings = FALSE)\n\n  # Export point clouds to numpy (.npy) files for use in python\n  mapply(write_pc_to_npy, \n        pc = pc_ls,\n        plot_id = plot_centers$plot_id,\n        pc_out_dir=PLOT_PC_DIR)\n\n  # Export ZQ95 values\n  als_derived_zq95_df &lt;- data.frame(plot_id = plot_centers$plot_id,\n                                    als_zq95 = as.numeric(als_derived_zq95_ls))\n\n  write.csv(als_derived_zq95_df, ZQ95_FPATH, row.names=FALSE)\n\n}\n\n\n# Load an example pc\ndemo_pc &lt;- np$load(list.files(PLOT_PC_DIR, full.names = TRUE)[50])\n\n# Visualize a point cloud\nplot_pc(demo_pc)\n\n\n\n\n\nLoad tree measurements\n\n# Load plot level tree measurements\ntrees_df &lt;- read_excel(PLOT_DATA_FPATH, sheet = 'Tree') %&gt;%\n              dplyr::rename(plot_id = PlotName,\n                            sp_code = tree_spec)\n\n\nhead(trees_df)\n\n# A tibble: 6 × 27\n  sp_code plot_id TreeID TreeSpec Origin Status   DBH CrownClass QualityClass\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       \n1       1 PRF001      24        1 P      D       10.1 &lt;NA&gt;       &lt;NA&gt;        \n2       1 PRF001      46        1 P      D        9.9 &lt;NA&gt;       &lt;NA&gt;        \n3       2 PRF001      20        2 N      L       67.5 D          A           \n4       2 PRF001      50        2 N      L       57.9 D          U           \n5       1 PRF001      10        1 N      L       55.9 D          A           \n6       1 PRF001      71        1 N      L       51.5 D          U           \n# ℹ 18 more variables: DecayClass &lt;dbl&gt;, Ht &lt;dbl&gt;, HLF &lt;dbl&gt;, HtFlag &lt;chr&gt;,\n#   phf &lt;dbl&gt;, baha &lt;dbl&gt;, CD_ht &lt;dbl&gt;, Int_ht &lt;dbl&gt;, BA_all &lt;dbl&gt;,\n#   TPH_all &lt;dbl&gt;, codom &lt;chr&gt;, domht &lt;dbl&gt;, ht_meas &lt;dbl&gt;, stems &lt;dbl&gt;,\n#   mvol &lt;dbl&gt;, tvol &lt;dbl&gt;, biomass &lt;dbl&gt;, size &lt;chr&gt;\n\n\nCompare 95th height percentiles derived from LiDAR with the 95th percentile of measured tree heights\n\nals_derived_zq95_df &lt;- read.csv(ZQ95_FPATH)\n\nfield_zq95_df &lt;- trees_df %&gt;%\n                filter(!is.na(ht_meas)) %&gt;%\n                group_by(plot_id) %&gt;%\n                summarize(field_zq95 = quantile(ht_meas, probs = 0.95))\n\nzq95_df &lt;- field_zq95_df %&gt;%\n              left_join(als_derived_zq95_df, by = 'plot_id')\n\nzq95_df %&gt;%\n  ggplot(aes(x = field_zq95, y = als_zq95)) + \n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n  theme_minimal() + \n  coord_fixed(ratio = 1)\n\n\n\n\n\n\n\n\nAdd species information to trees data\n\n# Load tree species codes\ntree_sp_codes_df &lt;- read.csv(TREE_SP_CODES_FPATH) %&gt;%\n                      mutate(species = trimws(species))\n\n\n# Add species names to trees df\ntrees_df &lt;- trees_df %&gt;% left_join(tree_sp_codes_df, \n                                   by = 'sp_code') \n\n\n# View unique species\nsort(round(table(trees_df['species']) / nrow(trees_df) * 100, 2), \n     decreasing = TRUE)\n\nspecies\n          Balsam fir           White pine     Red (soft) maple \n               14.69                14.66                13.12 \n            Red pine            Jack pine              Red oak \n               10.96                 4.74                 4.65 \n        White spruce             Tamarack          Sugar maple \n                4.61                 3.56                 3.51 \n     Trembling aspen             Ironwood       American beech \n                3.16                 1.97                 1.86 \n           Black ash          White birch     Largetooth aspen \n                1.79                 1.74                 1.56 \n        Yellow birch             Basswood Northern white cedar \n                0.99                 0.68                 0.47 \n     Eastern hemlock            White ash         American elm \n                0.37                 0.18                 0.09 \n        Black cherry        Balsam poplar \n                0.09                 0.02 \n\n\nClassify each plot as either dominated by coniferous or deciduous species.\n\nget_tvol_d_perc &lt;- function(trees){\n\n  decid_tvol &lt;- trees %&gt;% \n                  filter(sp_type == 'd') %&gt;%\n                  pull(tvol) %&gt;%\n                  sum()\n\n  plot_tvol &lt;- trees %&gt;% \n                  pull(tvol) %&gt;%\n                  sum()\n\n  perc_tvol_d &lt;- decid_tvol / plot_tvol * 100\n\n  return(perc_tvol_d)\n\n  }\n\nperc_d_vec &lt;- vector(mode = 'numeric')\n\nfor(plot_id_i in unique(trees_df$plot_id)){\n\n  plot_i_trees &lt;- trees_df[trees_df['plot_id'] == plot_id_i, ]\n\n  perc_d_vec &lt;- append(perc_d_vec, get_tvol_d_perc(plot_i_trees))\n\n}\n\n# Assing plot to be either coniferous or deciduous dominant\nperc_decid_df &lt;- data.frame(plot_id = unique(trees_df$plot_id),\n                            perc_decid = perc_d_vec) %&gt;%\n                  mutate(dom_sp_type = if_else(perc_decid &gt; 75, 'decid', \n                                       if_else(perc_decid &gt; 25 , 'mixed', 'conif')))\n\n\nhist(perc_decid_df$perc_decid)\n\n\n\n\n\n\n\nhead(perc_decid_df)\n\n  plot_id perc_decid dom_sp_type\n1  PRF001  4.6434971       conif\n2  PRF002  0.6137523       conif\n3  PRF003 62.1149520       mixed\n4  PRF004  0.0000000       conif\n5  PRF005  0.0000000       conif\n6  PRF006  0.0000000       conif\n\n\nDivide data into training, validation, and testing\n\n# Establish the number of samples per split\nn_test &lt;- round(nrow(perc_decid_df) * 0.20, 0)\n\nn_train &lt;-  round(nrow(perc_decid_df) * 0.60, 0)\n\nset.seed(14)\ntest_df &lt;- perc_decid_df %&gt;%\n    slice_sample(n=n_test) %&gt;%\n    mutate(split = \"test\")\n  \nset.seed(14)\ntrain_df &lt;- perc_decid_df %&gt;%\n    anti_join(test_df, by = \"plot_id\") %&gt;%\n    slice_sample(n=n_train) %&gt;%\n    mutate(split = \"train\")\n  \nval_df &lt;- perc_decid_df %&gt;%\n    anti_join(train_df, by = \"plot_id\") %&gt;%\n    anti_join(test_df, by = \"plot_id\") %&gt;%\n    mutate(split = \"val\")\n\n\n# Check splits\ncat(\n  sprintf(\"N Train Samples: %d (%.1f%%)\\n\", nrow(train_df), 100 * nrow(train_df) / nrow(perc_decid_df)),\n  sprintf(\"N Val Samples:   %d (%.1f%%)\\n\", nrow(val_df), 100 * nrow(val_df) / nrow(perc_decid_df)),\n  sprintf(\"N Test Samples:  %d (%.1f%%)\\n\", nrow(test_df), 100 * nrow(test_df) / nrow(perc_decid_df))\n)\n\nN Train Samples: 149 (59.8%)\n N Val Samples:   50 (20.1%)\n N Test Samples:  50 (20.1%)\n\n# Combine data frames\nlabels_df &lt;- dplyr::bind_rows(train_df, val_df, test_df)\n\n# View frequency by split\nggplot(labels_df, aes(x = split, fill = dom_sp_type)) +\n  geom_bar(position = \"dodge\") +\n  geom_text(stat = \"count\", aes(label = ..count..), \n            position = position_dodge(width = 0.9), vjust = -0.5, color = \"black\", size = 5) +\n  labs(x = \"Data Split\",\n       y = \"Number of Observations\",\n       fill = \"Dominant Species Type\") +\n  theme_minimal() +\n  scale_fill_brewer(\n    palette = \"Set2\",\n    labels = c(\"conif\" = \"Coniferous\", \"decid\" = \"Deciduous\", \"mixed\" = \"Mixed\")\n  )\n\n\n\n\n\n\n\nhead(labels_df)\n\n  plot_id  perc_decid dom_sp_type split\n1  PRF014  0.06404073       conif train\n2  PRF100  0.61206093       conif train\n3  PRF016 30.14652512       mixed train\n4  PRF155 10.49677683       conif train\n5  PRF220 52.17189106       mixed train\n6  PRF300  0.00000000       conif train\n\n\nExport labels\n\n# Ensure that labels correspond to existing point cloud files\npc_flist &lt;- list.files(PLOT_PC_DIR, full.names = TRUE)\npc_id_ls &lt;- gsub(\".npy\", \"\", basename(pc_flist))\n\n# Ensure labels contain the same plots as the ALS point clouds\nlabels_df &lt;- labels_df %&gt;% filter(plot_id %in% pc_id_ls)\n\n# Export labels\nwrite.csv(labels_df, LABELS_FPATH, row.names=FALSE)"
  },
  {
    "objectID": "02_data.html#summary-of-preprocessing-steps",
    "href": "02_data.html#summary-of-preprocessing-steps",
    "title": "Data Preparation",
    "section": "Summary of Preprocessing Steps",
    "text": "Summary of Preprocessing Steps\n\nExtract ALS point clouds corresponding to ground reference plots\nDenoise point clouds and normalize X and Y coordinates\nExport point clouds to numpy files for later use in model development\nCompare 95th height percentile of measured tree heights with ALS derived 95th height percentile\nDerive sample plot “labels”, establishing which plots are coniferous/deciduous/mixed\nSplit the data into training, validation, and test sets (i.e., splits)"
  },
  {
    "objectID": "index.html#relevant-resources",
    "href": "index.html#relevant-resources",
    "title": "Data Preparation",
    "section": "Relevant Resources",
    "text": "Relevant Resources"
  },
  {
    "objectID": "index.html#data-download",
    "href": "index.html#data-download",
    "title": "Data Preparation",
    "section": "Data download",
    "text": "Data download\nPRF 2018 sample plots have a 14.1 m radius (625 m2)\nThe preprocessed data folder can be downloaded here\nhttps://ln5.sync.com/dl/88a6f5dd0#u24mrtkh-d5dqhart-zrg42shx-jfhhk8u5\nThe original height normalized LiDAR and sample plot data for the PRF can be downloaded below:\nSPL LiDAR: https://opendata.nfis.org/downloads/petawawa/Raster/LiDAR_2018/PRF_benchmarking_harmonized_2018_ALS.zip\nField Plots: https://opendata.nfis.org/downloads/petawawa/Vector/Forest%20Sample%20Plots/SPL2018_EFI_ground_plots.zip"
  },
  {
    "objectID": "index.html#summary-of-preprocessing-steps",
    "href": "index.html#summary-of-preprocessing-steps",
    "title": "Data Preparation",
    "section": "Summary of Preprocessing Steps",
    "text": "Summary of Preprocessing Steps\n\nExtract ALS point clouds corresponding to ground reference plots\nNormalize X and Y coordinates\nCompare 95th height percentile of measured tree heights with ALS derived 95th height percentile\nDerive point cloud “labels”, establishing which plots are coniferous/deciduous/mixed\nSplit the data into training, validation, and test sets (i.e., splits)\nExport point clouds to numpy files for later processing"
  },
  {
    "objectID": "index.html#extract-lidar-point-clouds-using-the-lidr-package",
    "href": "index.html#extract-lidar-point-clouds-using-the-lidr-package",
    "title": "Data Preparation",
    "section": "Extract LiDAR point clouds using the lidR package",
    "text": "Extract LiDAR point clouds using the lidR package\nSet filepaths and other global parameters\n\nPROCESS_LIDAR = FALSE\n\nPLOT_RADIUS = 14.1\n\nPLOT_COORDS_FPATH = 'data/SPL2018_EFI_ground_plots/SPL2018_EFI_ground_plots/PRF_SPL2018_EFI_plots_pts_wgs84.shp'\n\nPLOT_DATA_FPATH = 'data/SPL2018_EFI_ground_plots/SPL2018_EFI_ground_plots/PRF_CNL_SPL_CalibrationData_LiveDeadStems.xlsx'\n\nTREE_SP_CODES_FPATH = 'data/mnrf_sp_codes.csv'\n\nLIDAR_DIR = 'E:/PRF/3_tiled_norm'\n\nPLOT_PC_DIR = \"data/plot_point_clouds\"\n\nLABELS_FPATH = 'data/labels.csv'\n\nZQ95_FPATH = 'data/zq95.csv'\n\nLoad required R packages\n\nlibrary(lidR)\nlibrary(here)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(mapview)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(reticulate)\n\n# Import python numpy module using reticulate in quarto\nnp &lt;- reticulate::import(\"numpy\")\n\nLoad the LiDAR and plot coordinates\n\n#Read the normalized las catalog\nctg &lt;- readLAScatalog(LIDAR_DIR)\n\n#Set some catalog processing parameters\nopt_select(ctg) &lt;- \"xyz\"\nopt_progress(ctg) &lt;- FALSE\n\n#Read the plot coordinates and ensure CRS is correct\nplot_centers &lt;- st_read(here(PLOT_COORDS_FPATH)) %&gt;%\n    st_transform(lidR::crs(ctg)) %&gt;%\n    st_zm() %&gt;%\n    dplyr::rename(plot_id = Plot)\n\n#Get vector representation of catalog area\nctg_sf &lt;- st_as_sf(lidR::as.spatial(ctg))\n\nmapview(ctg_sf, layer.name = 'LiDAR Tiles') + mapview(plot_centers, \n                                                      col.regions = 'red', \n                                                      color = 'black',\n                                                      layer.name = 'Ground Plots')\n\nDefine functions to process ALS data\n\nextract_pc &lt;- function(coords, ctg){\n\n      x = coords[1]\n      y = coords[2]\n\n      las &lt;- lidR::clip_circle(\n        las = ctg,\n        x = x,\n        y = y,\n        radius = PLOT_RADIUS)\n      \n      return(las)\n\n    }\n\nclean_pc &lt;- function(las) {\n  \n  las &lt;- lidR::filter_duplicates(las)\n  \n  las &lt;- lidR::classify_noise(las, sor(9,2))\n  \n  las &lt;- lidR::filter_poi(las, Classification != LASNOISE)\n  \n  return(las)\n}\n\npc_to_matrix &lt;- function(las){\n\n  pc &lt;- unname(st_coordinates(las))\n\n  return(pc)\n\n}\n\nnormalize_pc_xy &lt;- function(pc){\n\n  pc[, 1] &lt;- pc[, 1] - mean(pc[, 1])\n  pc[, 2] &lt;- pc[, 2] - mean(pc[, 2])\n\n  return(pc)\n}\n\ncalc_pc_zq95 &lt;- function(pc){\n\n    zq95 &lt;- quantile(pc[, 3], probs = 0.95)\n\n    return(zq95)\n\n}\n\nplot_pc &lt;- function(pc){\n\n  pc_df &lt;- as.data.frame(pc)\n  names(pc_df) &lt;- c('x', 'y', 'z')\n\n  p &lt;- plot_ly(pc_df, x = ~x, y = ~y, z = ~z, type = \"scatter3d\", mode = \"markers\",\n             marker = list(size = 3, color = ~z, colorscale = \"Jet\")) %&gt;%\n            layout(title = \"\",\n                  scene = list(\n                    xaxis = list(title = \"\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\"),\n                    yaxis = list(title = \"\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\"),\n                    zaxis = list(title = \"Z\", showgrid = FALSE, showticklabels = TRUE, ticks = \"outside\")\n                  ))\n\n  return(p)\n\n}\n\nwrite_pc_to_npy &lt;- function(pc, plot_id, pc_out_dir){    \n    \n    pc_np &lt;- np$array(pc, dtype = \"float32\")\n\n    np$save(file.path(here(pc_out_dir), paste0(plot_id, \".npy\")), pc_np)\n\n    return('')\n    \n    }\n\nExtract plot point clouds from full aquisition\n\nif(PROCESS_LIDAR){\n\n  # Get a list of plot coordinates\n  coords &lt;- split(st_coordinates(plot_centers), \n                    seq_len(nrow(plot_centers)))\n\n  # Extract point clouds and store in list\n  pc_ls &lt;- plyr::llply(coords, .fun = extract_pc, ctg = ctg, .progress='text')\n\n  # Clean point clouds\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = clean_pc, .progress='text')\n\n  # Convert point clouds to matrices\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = pc_to_matrix, .progress='text')\n\n  # Normalize point clouds X & Y coordinates (leave Z)\n  pc_ls &lt;- plyr::llply(pc_ls, .fun = normalize_pc_xy, .progress='text')\n\n  # Calculate zq95 for each point cloud to check alignment with plot data later\n  als_derived_zq95_ls &lt;- plyr::llply(pc_ls, .fun = calc_pc_zq95, .progress='text')\n\n  # Ensure the point cloud directory exists\n  dir.create(PLOT_PC_DIR, recursive = TRUE, showWarnings = FALSE)\n\n  # Export point clouds to numpy (.npy) files for use in python\n  mapply(write_pc_to_npy, \n        pc = pc_ls,\n        plot_id = plot_centers$plot_id,\n        pc_out_dir=PLOT_PC_DIR)\n\n  # Export ZQ95 values\n  als_derived_zq95_df &lt;- data.frame(plot_id = plot_centers$plot_id,\n                                    als_zq95 = as.numeric(als_derived_zq95_ls))\n\n  write.csv(als_derived_zq95_df, ZQ95_FPATH, row.names=FALSE)\n\n}\n\n\n\n# Load an example pc\ndemo_pc &lt;- np$load(list.files(PLOT_PC_DIR, full.names = TRUE)[50])\n\n# Visualize a point cloud\nplot_pc(demo_pc)\n\nLoad tree measurements\n\n# Load plot level tree measurements\ntrees_df &lt;- read_excel(PLOT_DATA_FPATH, sheet = 'Tree') %&gt;%\n              dplyr::rename(plot_id = PlotName,\n                            sp_code = tree_spec)\n\n\nhead(trees_df)\nCompare 95th height percentiles derived from LiDAR with the 95th percentile of measured tree heights\n\nals_derived_zq95_df &lt;- read.csv(ZQ95_FPATH)\n\nfield_zq95_df &lt;- trees_df %&gt;%\n                filter(!is.na(ht_meas)) %&gt;%\n                group_by(plot_id) %&gt;%\n                summarize(field_zq95 = quantile(ht_meas, probs = 0.95))\n\nzq95_df &lt;- field_zq95_df %&gt;%\n              left_join(als_derived_zq95_df, by = 'plot_id')\n\nzq95_df %&gt;%\n  ggplot(aes(x = field_zq95, y = als_zq95)) + \n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"red\") +\n  theme_minimal() + \n  coord_fixed(ratio = 1)\n\nAdd species information to trees data\n\n# Load tree species codes\ntree_sp_codes_df &lt;- read.csv(TREE_SP_CODES_FPATH) %&gt;%\n                      mutate(species = trimws(species))\n\n\n# Add species names to trees df\ntrees_df &lt;- trees_df %&gt;% left_join(tree_sp_codes_df, \n                                   by = 'sp_code') \n\n\n# View unique species\nsort(round(table(trees_df['species']) / nrow(trees_df) * 100, 2), \n     decreasing = TRUE)\n\nClassify each plot as either dominated by coniferous or deciduous species.\n\nget_tvol_d_perc &lt;- function(trees){\n\n  decid_tvol &lt;- trees %&gt;% \n                  filter(sp_type == 'd') %&gt;%\n                  pull(tvol) %&gt;%\n                  sum()\n\n  plot_tvol &lt;- trees %&gt;% \n                  pull(tvol) %&gt;%\n                  sum()\n\n  perc_tvol_d &lt;- decid_tvol / plot_tvol * 100\n\n  return(perc_tvol_d)\n\n  }\n\nperc_d_vec &lt;- vector(mode = 'numeric')\n\nfor(plot_id_i in unique(trees_df$plot_id)){\n\n  plot_i_trees &lt;- trees_df[trees_df['plot_id'] == plot_id_i, ]\n\n  perc_d_vec &lt;- append(perc_d_vec, get_tvol_d_perc(plot_i_trees))\n\n}\n\n# Assing plot to be either coniferous or deciduous dominant\nperc_decid_df &lt;- data.frame(plot_id = unique(trees_df$plot_id),\n                            perc_decid = perc_d_vec) %&gt;%\n                  mutate(dom_sp_type = if_else(perc_decid &gt; 75, 'decid', \n                                       if_else(perc_decid &gt; 25 , 'mixed', 'conif')))\n\n\nhist(perc_decid_df$perc_decid)\n\nhead(perc_decid_df)\n\nDivide data into training, validation, and testing\n\n# Establish the number of samples per split\nn_test &lt;- round(nrow(perc_decid_df) * 0.20, 0)\n\nn_train &lt;-  round(nrow(perc_decid_df) * 0.60, 0)\n\nset.seed(14)\ntest_df &lt;- perc_decid_df %&gt;%\n    slice_sample(n=n_test) %&gt;%\n    mutate(split = \"test\")\n  \nset.seed(14)\ntrain_df &lt;- perc_decid_df %&gt;%\n    anti_join(test_df, by = \"plot_id\") %&gt;%\n    slice_sample(n=n_train) %&gt;%\n    mutate(split = \"train\")\n  \nval_df &lt;- perc_decid_df %&gt;%\n    anti_join(train_df, by = \"plot_id\") %&gt;%\n    anti_join(test_df, by = \"plot_id\") %&gt;%\n    mutate(split = \"val\")\n\n\n# Check splits\ncat(\n  sprintf(\"N Train Samples: %d (%.1f%%)\\n\", nrow(train_df), 100 * nrow(train_df) / nrow(perc_decid_df)),\n  sprintf(\"N Val Samples:   %d (%.1f%%)\\n\", nrow(val_df), 100 * nrow(val_df) / nrow(perc_decid_df)),\n  sprintf(\"N Test Samples:  %d (%.1f%%)\\n\", nrow(test_df), 100 * nrow(test_df) / nrow(perc_decid_df))\n)\n\n# Combine data frames\nlabels_df &lt;- dplyr::bind_rows(train_df, val_df, test_df)\n\n# View frequency by split\nggplot(labels_df, aes(x = split, fill = dom_sp_type)) +\n  geom_bar(position = \"dodge\") +\n  geom_text(stat = \"count\", aes(label = ..count..), \n            position = position_dodge(width = 0.9), vjust = -0.5, color = \"black\", size = 5) +\n  labs(x = \"Data Split\",\n       y = \"Number of Observations\",\n       fill = \"Dominant Species Type\") +\n  theme_minimal() +\n  scale_fill_brewer(\n    palette = \"Set2\",\n    labels = c(\"conif\" = \"Coniferous\", \"decid\" = \"Deciduous\", \"mixed\" = \"Mixed\")\n  )\n\nhead(labels_df)\n\nExport labels\n\n# Ensure that labels correspond to existing point cloud files\npc_flist &lt;- list.files(PLOT_PC_DIR, full.names = TRUE)\npc_id_ls &lt;- gsub(\".npy\", \"\", basename(pc_flist))\n\n# Ensure labels contain the same plots as the ALS point clouds\nlabels_df &lt;- labels_df %&gt;% filter(plot_id %in% pc_id_ls)\n\n# Export labels\nwrite.csv(labels_df, LABELS_FPATH, row.names=FALSE)"
  },
  {
    "objectID": "02_data.html#dataset-background",
    "href": "02_data.html#dataset-background",
    "title": "Data Preparation",
    "section": "Dataset Background",
    "text": "Dataset Background\nThe Petawawa Resereach Forest (PRF) is the oldest research forest in Canada, established in 1918. It is a remote sensing supersite and is part of the GEO-TREES network.\nIn this workshop make use of enhanced forest inventory sample plots collected in the PRF in 2018. We are also using single photon airborne laser scanning (ALS) data also collected in 2018.\nThe sample plots have a 14.1 m radius (625 m2).\nThe ALS data has a mean point density of 34.6 points/m2.\nThe preprocessed data can be downloaded here:\nhttps://ln5.sync.com/dl/88a6f5dd0#u24mrtkh-d5dqhart-zrg42shx-jfhhk8u5\nThe original height normalized ALS and sample plot data for the PRF can be downloaded from:\nSPL LiDAR: https://opendata.nfis.org/downloads/petawawa/Raster/LiDAR_2018/PRF_benchmarking_harmonized_2018_ALS.zip\nField Plots: https://opendata.nfis.org/downloads/petawawa/Vector/Forest%20Sample%20Plots/SPL2018_EFI_ground_plots.zip"
  },
  {
    "objectID": "02_data.html#data-i",
    "href": "02_data.html#data-i",
    "title": "Data Preparation",
    "section": "Data I",
    "text": "Data I\nPRF 2018 sample plots have a 14.1 m radius (625 m2)\nThe preprocessed data folder can be downloaded here\nhttps://ln5.sync.com/dl/88a6f5dd0#u24mrtkh-d5dqhart-zrg42shx-jfhhk8u5\nThe original height normalized LiDAR and sample plot data for the PRF can be downloaded below:\nSPL LiDAR: https://opendata.nfis.org/downloads/petawawa/Raster/LiDAR_2018/PRF_benchmarking_harmonized_2018_ALS.zip\nField Plots: https://opendata.nfis.org/downloads/petawawa/Vector/Forest%20Sample%20Plots/SPL2018_EFI_ground_plots.zip"
  },
  {
    "objectID": "02_data.html",
    "href": "02_data.html",
    "title": "Data Preparation",
    "section": "",
    "text": "This section will provide preprocessing code to prepare LidAR and sample plot data for subsequent point cloud deep learning model development."
  }
]